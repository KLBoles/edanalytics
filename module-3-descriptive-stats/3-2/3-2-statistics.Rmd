---
title: "Descriptive Statistics"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r load, include=FALSE}
library(learnr)
library(tidyverse)
library(ggthemes)
library(psych)
tutorial_options(exercise.timelimit = 60)
```

## Introduction

Congratulations, you've made it to the final tutorial of this course! Now that we understand foundational statistical concepts, in this final tutorial we will learn how to generate descriptive statistics using R.

In this final tutorial, we will cover the following:

- Summary statistics
- Measures of central tendency
- Measures of dispersion
- Distribution shape
- Frequency tables

Great, let's get started!

## Summary Statistics

We're going to return back and use the General Social Survey (GSS) built in dataset for this final tutorial.

```{r setup, include=TRUE}
gss <- forcats::gss_cat
gss
```

#### Describe

We've introduced the `describe()` function in the second module, but we will review it once more in this tutorial.

The `describe()` function is a useful function in first getting to know your data. For this function, you provide the name of the data frame as the first argument of the function. The output provides the following for each variable in the dataset: the number of observations (n), and several descriptive statistics (e.g., mean, standard deviation, standard error, etc.). 

Do you remember why certain variables  have asterisk next to their names? The asterisk is an indicator that these variables are factor variables! In the `gss` data set, it shows that `marital`, `race`, `rincome`, `partyid`, `relig`, and `denom` are all factor variables. But isn't it strange that these variables still have descriptive statistics associated with them? Good point. The descriptive statistics provided by `describe()` for each of these variables is meaningless so it would be best to ignore these statistics. It's like trying to take the mean of the colors in a crayon box, you can't! However, the descriptive statistics provided for the variables of integer values is quite useful. For example, the average age of respondents in this sample data set is approximately 47 years old. 

```{r dsecribe, exercise = TRUE}
psych::describe(gss)
```

Here's a list of all the descriptive statistics given when using `describe()`

- vars: the number of variables presented cumulatively
- n: number of valid cases
- mean: average (if applicable)
- sd: standard deviation (if applicable)
- median: standard or interpolated median (if applicable)
- trimmed: trimmed mean defaulting to .1 (if applicable)
- mad: median absolute deviation (if applicable)
- min: minimum value (if applicable)
- max: maximum value (if applicable)
- range: range of values (if applicable)
- skew: skewness (if applicable)
- kurtosis: kurtosis (if applicable)
- se: standard error (if applicable)

#### Summary

The `summary()` function is a base R function that can be used to generate quick descriptive statistics. Similar to the `describe()` function, you provide the name of the dataframe you wish to generate descriptive statistics.

```{r summary, exercise = TRUE}
summary(gss)
```

The `summary()` function calculate and returns the minimum value, the 1st quartile value (25th percentile), the median value, the 3rd quartile value (75th percentile), and the maximum value for numeric values. If there are factors in the dataset, the function returns the counts for each of the factor levels (or groups) for each variable. If there are `NA`s in the dataset, `summary()` excludes these cases from being counted in the output. 

#### Five-Number Summary

The `fivenum()` function returns five summary statistics: the minimum value, 25th percentile, median (or 50th percentile) 75th percentile, and maximum value for the input data. Let's use the `fivenum()` function for the age variable in the gss dataset. 

```{r fivenum, exercise = TRUE}
fivenum(gss$age)
```
Please note, that the `fivenum()` function only accepts numeric input values. You will receive an error if you provide data that are factors or characters.

Great! These are quick and easy ways to generate a comprehensive output of descriptive statistics.

## Measures of Central Tendency

A measure of central tendency is a single value that describes the central position of a dataset with numeric values. Measures of central of tendency include mean (the average), median, and mode. While these are all valid measures of central tendency, there are certain conditions were some of these measures are more appropriate than others.

### Mean

We can find the mean by providing a vector of numeric values to the built in R function `mean()`. Note, this function does not exclude `NA` cases so we have to tell R to only include complete observations.

```{r mean, exercise = TRUE}
mean(gss$age, na.rm = TRUE)
```

Using mean as a measure of central tendency is appropriate if we have interval/ratio variables that normally distributed with no outliers. If the data are skewed, the median is a more appropriate measure of central tendency to calculate for interval/ratio variables.

### Median

Like the `mean()` function, we can find the median by providing a vector of numeric values to the built in R function `median()`. Note, this function does not exclude `NA` cases so we have to tell R to only include complete observations.

```{r median, exercise = TRUE}
median(gss$age, na.rm = TRUE)
```

As mentioned previously, the median is the most appropriate measure of central tendency for skewed interval/ratio data as well as ordinal data.

### Mode

Unlike `mean()` there is no built in R function to calculate the mode. However, you can install and load the package `DescTools` package and use their `Mode()` function to calculate the mode. Alternatively, we could write a simple function to compute the mode. Mode is the most appropriate measure of central tendency when we have nominal (categorical) data.

```{r mode, exercise = TRUE}
compute_mode <- function(x) {
  unique_x <- unique(x)
  counts <- tabulate(match(x, unique_x))
  unique_x[which.max(counts)]
}

compute_mode(gss$age)

```


## Measures of Dispersion

Measures of dispersion describes the spread of data. Common measures of data dispersion include variance, standard deviation, and range.

### Variance

The `var()` function calculates the variance of a numeric vector. Variance measures how much data are spread out and is mathematically defined as the average of squared differences from the mean. Note, this function does not exclude `NA` cases so we have to tell R to only include complete observations.

```{r var, exercise = TRUE}
var(gss$age, na.rm = TRUE)
```

Variance is difficult to interpret since it is in squared units. Instead we take the square root of the variance to calculate the standard deviation (which is the most commonly used measure of dispersion). 

### Standard Deviation

The `sd()` function calculates the standard deviation of a numeric vector. Standard deviation also measures how much data are spread out and is mathematically defined as each data point's deviation relative to the mean. Note, this function does not exclude `NA` cases so we have to tell R to only include complete observations.

```{r sd, exercise = TRUE}
sd(gss$age, na.rm = TRUE)
```

### Range

The range is also another measure of dispersion and be calculated using `range()` function. The output of this functions tells us the minimum value of a numeric vector as well as the maximum value. 

```{r range, exercise = TRUE}
range(gss$age, na.rm = TRUE)
```

## Distribution shape

The shape of the distribution of data can have important implications on our data analytic choices. Examining the skewness and kurtosis are two ways of checking the distribution shape of our data.

### Skewness

Skewness measures the symmetry of our data. Symmetrical data follows the shape of a classic bell curve where the left side of the data is identical to the right side up until the middle point (if you were to fold the distribution vertically in half). A symmetric distribution is where the mean, median, and mode for the data are all the same.

```{r normdist, echo=FALSE, out.width="75%"}
knitr::include_graphics(paste0(getwd(), "/images/norm-dist.png"))

```

A right-skewed distribution (positively skewed) has a long right tail with the mean closest to the tail compared to the mode and median. 

```{r rskewdist, echo=FALSE, out.width="75%"}
knitr::include_graphics(paste0(getwd(), "/images/rskew-dist.png"))

```

A left-skewed distribution (negatively skewed) has a long left tail with the mean closest to the tail compared to the mode and median. 

```{r lskewdist, echo=FALSE, out.width="75%"}
knitr::include_graphics(paste0(getwd(), "/images/lskew-dist.png"))

```

The best way we can examine the distribution of a dataset is to plot it using the `hist()` function! Let's examine the density of the `age` variable in the `gss` dataset.

```{r skew, exercise = TRUE}
hist(gss$age, freq = FALSE)
lines(density(gss$age, na.rm= TRUE), col = "blue")   
```

Let's now examine the density of the `tvhours` variable in the `gss` dataset.
```{r skew2, exercise = TRUE}
hist(gss$tvhours, freq = FALSE)
lines(density(gss$tvhours, na.rm= TRUE), col = "blue")   
```

We can also calculate the skewness values using the `describe()` function in the `psych` package!

```{r skew3, exercise = TRUE}
psych::describe(gss$age)  
psych::describe(gss$tvhours)  
```

What do you make of these skewness values?

Below is a brief guideline for skewness benchmarks.

- Symmetric: Values between -0.5 to 0.5
- Moderated Skewed data: Values between -1 and -0.5 or between 0.5 and 1
- Highly Skewed data: Values less than -1 or greater than 1

### Kurtosis

Kurtosis measures the tailedness of data distribution. In other words, kurtosis measures the degree to which data points cluster in the tails or peak of the distribution. 

```{r kurt, echo=FALSE, out.width="75%"}
knitr::include_graphics(paste0(getwd(), "/images/kurt.png"))

```

There are 3 types of kurtosis:

- Mesokurtic: Normally distributed data. Kurtosis value of 0 indicates a normally distributed data
- Leptokurtic: Distribution has a sharp peak and fatter tails. Kurtosis is positive with a value > 3
- Platykurtic: Distribution has a lower and wider peak with thinner tails. Kurtosis is negative with a value < 3 

Similar to skewness, we can assess kurtosis by plotting the density of our data using a histogram. We can also use the `describe()` function in the `psych` package to assess kurtosis.

```{r kurt2, exercise = TRUE}
psych::describe(gss$age)  
psych::describe(gss$tvhours)  
```

What do you think of the kurtosis values of the data for the `age` and `tvhours` variables in the `gss` dataset?

## Frequency Tables

Frequency tables are important to generate when trying to get a better understanding of a dataset. Frequency tables show the distribution (or counts) of observations that occur based on the option within a variable. They are helpful to understand which options occur more or less often in a dataset. 

### Table
We can generate a frequency table by using the `table()` function in base R. Frequency tables can be used for nominal, ordinal, interval, and ratio data. However, frequency tables may be more appropriate for nominal, ordinal, and (at times) interval data.

Let's walk through a few examples.

Let's generate a frequency table for the age variable in the gss dataset.

```{r table1, exercise = TRUE}
table(gss$age)  
```

In looking at the youngest and oldest respondents, we have 91 respondents in the gss dataset who reported their age as 18 years old and 148 respondents who reported their age as 89. However, frequency tables can be less useful if there are too many response options for a variable (such as the age variable in the gss dataset). It might be more helpful to create groups to better digest the data.

Let's wrangle the data.
```{r wrangle, exercise = TRUE}
d <- gss |>
  mutate(age_groups = case_when(age >= 20 & age <= 29 ~ "20s",
                         age >= 30 & age <= 39 ~ "30s", 
                         age >= 40 & age <= 49 ~ "40s",
                         age >= 50 & age <= 59 ~ "50s",
                         age >= 60 & age <= 69 ~ "60s",
                         age >= 70 & age <= 79 ~ "70s",
                         age >= 80 ~ "80s",
                         TRUE ~ as.character(age)))

```

Let's generate a frequency table with the wrangled data.
```{r table2, exercise = TRUE, exercise.setup  = "wrangle" }
table(d$age_groups) 
```

Much better and more informative!

Great, let's generate a frequency table for `tvhours`.
```{r table3, exercise = TRUE}
table(gss$tvhours)  
```

The frequency table for the `tvhours` variable isn't too clustered like the age variable was in the initial frequency table we created. The output is useful as is for `tvhours`.

### Count

We can also generate frequency tables by using the `count()` function in the tidyverse :)

```{r count, exercise = TRUE}
gss |>
  count(tvhours)
```

Nice!

We can also easily sort our data using the `count()` function. 

```{r count2, exercise = TRUE}
gss |>
  count(tvhours, sort = TRUE)
```

We can also generate a frequency table by multiple variables.

```{r count3, exercise = TRUE}
gss |>
  count(marital, race, sort = TRUE)
```

## Tasks

Now that we have completed the final module on descriptive statistics, let's engage in the final task for this course.

1. Open the last R you created in the previous module. Go ahead and run this script to make sure your code works (we are going to pick up where we left off last time).
2. Generate descriptive statistics for each variable in the `hsbtransformed` dataset
3. Please list the level of measurement for each variable (e.g., nominal, ordinal, interval, ratio) and your justification.
4. Please list and report the appropriate central tendency measure for each variable and your justification.
5. Report the skewness and kurtosis for each variable.
6. Please pick three variables and generate a frequency table for each of these variables. Is there anything interesting based on these frequency tables?
7. What do you find interesting or are you curious about regarding the statistics generated from this dataset?

### Reflect
Now that you have completed the final task for the course, let's take some time to reflect. What is one thing that surprised you? What is one thing that confused you? Did you learn anything that might be useful in the type of work you do?

Now let's reflect on the overall course. Please post your responses to the canvas discussion board.
1. What is something you found the most challenging in this course? Why?
2. What is something you found the most enjoyable in this course? Why?
3. What is something you want to learn more about?
4. Is there something that you can directly apply to the type of work you do?
5. How confident are you in your R skills after completing this course?
6. Is there anything else you would like to include that we didn't ask?

### El Fin
Good job on completing this course! We hope you enjoyed learning the basics of educational data analytics using R as much as we did!